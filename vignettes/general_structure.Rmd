---
title: "General structure"
author: "Carlos Varela MartÃ­n"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Welcome to eflows. eflows is a package aimed at simulation and real-time steering of Energy Management Systems. The package revolves around two concepts 

## Simulation

It provides a *tidyverse* consistent API that allows to combine different elements of an energy system, and to predict how will the flows of energy between them look like. This include: 

- Production of renewable energies
- Consumption of energy
  - Regular household use
  - Electric Vehicles
  - Heat pumps
- Stationary batteries
- Grid constrains.

These sort of calculations will be of particular importance in the near future as the electrification of the energy system takes place. Particularly, the rise of Electric Vehicles and heat pumps will add pressure over the electricity distribution system, making harder to match the production and demand of energy. 

## Timeshifting

The core idea is estimating how the demand of energy can be *shifted*, so it can be accomodated to the production of energy (normally due to the variability of renewable energies). We distingish between: 

- Foreshifting: The energy that would be consumed in the present moment is instead consumed in the future. It normally apply to EVs. Other household applications are also subject to this kind of demand-side management, but the EVs will be by far the application that will consume the most energy. 

- Backshifting: The energy that would be consumed in the near future is instead consumed in the present moment. There are a couple of relevant subcategories here: 
  - Buffer mode: The energy is stored in advance, but it is lost as it remains stored. There is a tradeoff, then, between the advantages of storing the energy in advance and losing some energy as it is stored. It is typical of the heat buffers used in combination with heat pumps. 
  - Storage mode: The energy is stored with neglectible loses over time, but *at a cost*. Typical of lithium-ion batteries, where there are some loses due to the conversion of energy to the battery and from the battery. 
  
## Principles
  
eflows strives to be a declarative package and probably requires a lot of documentation. In this file I strive to write some of the principles that govern the API and the design of the package

### Use of dataframes with the first column as POSIXt object
Time plays a vital role in eflows, yet the time series objects are not prefered. Instead, are used liberally data frames where the first column is time-based (and normally named "datetime"). This decision is taken for the sake of simplicity; a time series most of the times behaves like a data frame wehre the first column has different semantics. Where it is necessary to operate with actual time series, two helping functions to flip between data frames and time series are used: `df_to_ts` and `ts_to_df`


### Based on energy, not power
The energy flows are expressed on basis of kWh (the default unit to work with in the package), not kW or any other power unit. In principle kWh and kW are equivalent if the time step is one hour. This makes easier to read the changes in the battery: "25 kWh have flown, so the battery is charged with extra 25 kWh"

### Left-aligned
The time-based data is left aligned. This means that the changes in flows and battery soc reflect the change of the system once that time step has been concluded. In an hourly-based simulation, the flows that correspond to 14:00 are the ones happened between 14:00 and 15:00, and the soc of the batteries reflect their status once these energy flows have been resolved.

## Functional Programming (FP) vs Object-Oriented Programming (OOP)
FP values high abstraction levels and a clear differentiation between data and functions. It also have **value semantics**, meaning the result of a function is always a different object than the inpu, a copy. This is in general good news because it is easier to reason about what a programme does. It is the preferred way of working with R, and it suits particularly well data analyis. 

OOP relies on data structures (classes) that also encapsulates a number of functions that act *over them* (refering in their arguments as *self*), here called "methods". By convention, any method, besides its side effect, returns *self*. In addition, OOP relies in **reference semantincs**, meaning any change a method does over an object is applied directly to the object, without need of making a copy. 

OOP make it harder to reason about what a programme does, because the "referential transparency" and the "immutability" are not preserved. The "lineal" train of thought that can be appplied to FP does not exist here, but this might be an advantage in certain situations, particularly in interactive environments. R, while functional at its core, has several ways to approach OOP, the most used of which is the called *S3* system. S3 is a very simple OO approach, where methods are not encapsulated with the data. The overall result is that a function behaves differently depending on the class of the argument passed to it. 

Fully functional OOP in R is an aftertought, introduced with the R6 classes. As eflows relies on a lot of data relating properly with each other, it seems like a good idea to ue these R6 classes to organize data in input-validated ways, and then use methods to execute otherwise functions over this data. 

The main class used by the eflows pakcage is the `e_frame`, which in turn contains other objects, that loosely correnpond to the different "components" of the energy system. for instance, the attribute `demand` of an e_frame object is in turn an `e_demand` object, with its own methods and attributes, and more important: with its own set of attributes, both as "inputs" and as "outputs". This allows some flexibility in using different "chuks" of an e_frame object in a more or less independent way. 

While eflows use reference semantics, it tries to maintain the advantages of FP by making all the methods used *idempotent*, meaning an object is not going to change more than one time if the same method is passed to an object two or more times. This means that there are not methods such as `add_battery()`, where data of successive batteries are attached to the e_frame object. Instead, there is `set_battery()`, and the whole value of battery is substituted every time the method is run. 


## Internal work
The concerns of eflows are divided in three main "layers", from the core up: 

- C++ algorithms (internals)
The concept of eflows require of nested "for loops" and other imperative programming structured that are famously slow in R, and at loggerheads with the functional paradigm of the language. The solution for both problems is to use C++ code that takes care of the "heavy lifting". The user is not supposed to be able to access the C++ functions, that are wrapped instead by R functions. 

This is facilitated by the *Rcpp* package, that allows to directly combine R and C++ code. Remarkably, Rcpp defines classes to pass R calls and R environments as arguments of a C++ function, what allows to work with arbitrary code and data at C++ speed withot the need of recompile.   

the C++ functions do not do any input verification (so they can be reused easily in other high-performance processes), and are named in camelCase to distinguish them from their R wrappers (in case of ambiguity, it is added `Cpp` at the end).

Although I experimented with several C++ files, one for each C++ algorithm, the difficulty at sharing auxiliary functions convinced me of having just one file with all the relevant functions appropiately documented. 

- R functions (exposed)
R functions wrap the C++ internals. In this middle layer there are a couple of main things happening: 

- There is input validation (I try to be strict in eflows about the sort of data accepted, and to make the functions "fail fast" instead of giving some obscure error)
- There is input transformation: sometimes the arguments that are consumed by the C++ function are of different classes that the ones passed onto the R function. In addition, I try to be flexible with the input of the R functions, in the sense that instead of a "list of one", the function can accept that object, and the middle layer will include it into a list before passing it to C++

While it is possible to work directly with these functions, the intention is to manage the expectable entropy of the projects by providing a system of classes to organize and work with the data. 

- R6 classes (exposed)










-----------------

The C++ functions require to pass each argument in an individual way, while the R functions are made to work with methods, and are more directly executable. 

C++ functions are named in camelCase and suffixed by Cpp, to let clear that are the "core" functions. 

Some functions may also include or not the suffix Unsafe, to indicate that are faster but have no way to control wether they are doing the right check control of inputs

Functional and OO design: the objects "are stuff" that are subject to functions. Manage project entropy

Nesting: Objects&methods(R functions(Cppfunctions())
Then, the objects are manipulated by other functions.

Objects: 
- Use functions to modify objects, or to "exercise" something over objects
- Use methods so you "extract something through an object", or to get a result from an object that doesn't depend of other stuff except the fields of an object. 
Most probably, more than objects what you want to do is to create active bindings so you can "extract" something while computating it. 

At least you can make the methods of a call "idempotent". If you call them twice, it is ok, in this way the object behaves a bit in a "quasifunctional" way. 

Remember: you can change R6 classes with $set
